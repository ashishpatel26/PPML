{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-Differentially-Private-Logistic-Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQkxvKRNJmAW"
      },
      "source": [
        "First, let us load the training and testing data from the adult dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjsi2-HkJUQ3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "                        usecols=(0, 4, 10, 11, 12), delimiter=\", \")\n",
        "\n",
        "y_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "                        usecols=14, dtype=str, delimiter=\", \")\n",
        "\n",
        "X_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
        "                        usecols=(0, 4, 10, 11, 12), delimiter=\", \", skiprows=1)\n",
        "\n",
        "y_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
        "                        usecols=14, dtype=str, delimiter=\", \", skiprows=1)\n",
        "y_test = np.array([a[:-1] for a in y_test])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK5uhd26JtUD"
      },
      "source": [
        "For diffprivlib, LogisticRegression works best when the features are scaled, to control the norm of the data. To streamline this process, we create a Pipeline in sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpJYtqQoJu_-"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "lr = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('clf', LogisticRegression(solver=\"lbfgs\"))\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFyBGg-TJvzk"
      },
      "source": [
        "## Logistic Regression with No Privacy\n",
        "To begin, let's first train a regular (non-private) logistic regression classifier, and test its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqjIoAguJ3aO",
        "outputId": "6fc6b16c-7aa0-44bd-d1ba-074b6ac55ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Non-private test accuracy: %.2f%%\" % (accuracy_score(y_test, lr.predict(X_test)) * 100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Non-private test accuracy: 81.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MxF6GbMJ80u"
      },
      "source": [
        "## Differentially Private Logistic Regression\n",
        "First, install IBM Differential Privacy Library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjShu6pyJ_bV",
        "outputId": "0adcad8c-ece3-48ef-ebcd-4c94877cfb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install diffprivlib"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting diffprivlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/b8/852409057d6acc060f06cac8d0a45b73dfa54ee4fbd1577c9a7d755e9fb6/diffprivlib-0.3.0.tar.gz (70kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.18.5)\n",
            "Requirement already satisfied: setuptools>=39.0.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (50.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.17.0)\n",
            "Building wheels for collected packages: diffprivlib\n",
            "  Building wheel for diffprivlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffprivlib: filename=diffprivlib-0.3.0-cp36-none-any.whl size=138999 sha256=e8c0a87fdd7df12b5632f3fe4e3828b99928f2171b5758074ccd43ae06c4d57d\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/68/62/617183f73d3feceab2c9d4081714a27bc11be5bb3f10f59b8a\n",
            "Successfully built diffprivlib\n",
            "Installing collected packages: diffprivlib\n",
            "Successfully installed diffprivlib-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAO0X22ZKAkM"
      },
      "source": [
        "Using the diffprivlib.models.LogisticRegression module of diffprivlib, we can train a logistic regression classifier while satisfying differential privacy. If we don't specify any parameters, the model defaults to epsilon = 1 and data_norm = None. If the norm of the data is not specified at initialization (as in this case), the norm will be calculated on the data when .fit() is first called and a warning will be thrown as it causes a privacy leak. To ensure no additional privacy leakage, we should specify the data norm explicitly as an argument, and choose the bounds independently of the data (i.e. using domain knowledge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTPEn0xbKFRi",
        "outputId": "dabdb678-e119-48d7-ab51-e26be8e6e68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import diffprivlib.models as dp\n",
        "dp_lr = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('clf', dp.LogisticRegression())\n",
        "])\n",
        "\n",
        "dp_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Differentially private test accuracy (epsilon=%.2f): %.2f%%\" % \n",
        "     (dp_lr['clf'].epsilon, accuracy_score(y_test, dp_lr.predict(X_test)) * 100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Differentially private test accuracy (epsilon=1.00): 80.55%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/diffprivlib/models/logistic_regression.py:224: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
            "  \"privacy leakage, specify `data_norm` at initialisation.\", PrivacyLeakWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9dN3rBqKJTd"
      },
      "source": [
        "As we can see from the output accuracies above, the regular (non-private) logistic regression classifier could produce an accuracy of 81.04%, while setting epsilon=1.00, the differentially private Naïve Bayes classifier could achieve an accuracy of 80.93%. If we use a smaller epsilon, it usually leads to better privacy protection while less accuracy. For instance, if we set epsilon=0.01:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGwF-7FKLfV",
        "outputId": "c185c9df-c45a-42f3-8231-df7aa871ccc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import diffprivlib.models as dp\n",
        "dp_lr = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('clf', dp.LogisticRegression(epsilon=0.01))\n",
        "])\n",
        "\n",
        "dp_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Differentially private test accuracy (epsilon=%.2f): %.2f%%\" % \n",
        "     (dp_lr['clf'].epsilon, accuracy_score(y_test, dp_lr.predict(X_test)) * 100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Differentially private test accuracy (epsilon=0.01): 71.25%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/diffprivlib/models/logistic_regression.py:224: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
            "  \"privacy leakage, specify `data_norm` at initialisation.\", PrivacyLeakWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}